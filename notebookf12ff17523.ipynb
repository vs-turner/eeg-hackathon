{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":218459,"sourceType":"datasetVersion","datasetId":93959}],"dockerImageVersionId":30042,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task for Today  \n\n***\n\n## EEG Emotion Prediction  \n\nGiven *EEG data from subjects who were watching movies*, let's try to predict the **emotional state** of a subject during a given movie.  \n  \nWe will use a TensorFlow recurrent neural network to make our predictions.","metadata":{}},{"cell_type":"markdown","source":"# Getting Started","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/eeg-brainwave-dataset-feeling-emotions/emotions.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = data.loc[0, 'fft_0_b':'fft_749_b']\n\nplt.figure(figsize=(16, 10))\nplt.plot(range(len(sample)), sample)\nplt.title(\"Features fft_0_b through fft_749_b\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_mapping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    df['label'] = df['label'].replace(label_mapping)\n    \n    y = df['label'].copy()\n    X = df.drop('label', axis=1).copy()\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n    \n    return X_train, X_test, y_train, y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(X_train.shape[1],))\n\nexpand_dims = tf.expand_dims(inputs, axis=2)\n\ngru = tf.keras.layers.GRU(256, return_sequences=True)(expand_dims)\n\nflatten = tf.keras.layers.Flatten()(gru)\n\noutputs = tf.keras.layers.Dense(3, activation='softmax')(flatten)\n\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=50,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=5,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"model_acc = model.evaluate(X_test, y_test, verbose=0)[1]\nprint(\"Test Accuracy: {:.3f}%\".format(model_acc * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(X_test))))\n\ncm = confusion_matrix(y_test, y_pred)\nclr = classification_report(y_test, y_pred, target_names=label_mapping.keys())\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\nplt.xticks(np.arange(3) + 0.5, label_mapping.keys())\nplt.yticks(np.arange(3) + 0.5, label_mapping.keys())\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\\n----------------------\\n\", clr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps://youtu.be/IAQdqaoHrfE","metadata":{}}]}